{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borali, Beril\n",
    "# 300036112\n",
    "# Assignment 2\n",
    "# CSI 5155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "palestinian-bottom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree,  svm, neighbors, ensemble, metrics,  model_selection, neural_network # , make_pipeline\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn import pipeline \n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn import over_sampling, under_sampling\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0674bac-e265-4e55-a0c8-5b6e8beeb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /opt/anaconda3/bin/python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floating-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"./data/drug/drug_consumption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparative-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=[\"ID\",\"Age\",\"Gender\",\"Education\",\"Country\",\"Ethnicity\",\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\",\n",
    "             \"Alcohol\",\"Amphet\",\"Amyl\",\"Benzos\",\"Caff\",\"Cannabis\",\"Choc\",\"Coke\",\"Crack\",\n",
    "             \"Ecstasy\",\"Heroin\",\"Ketamine\",\"Legalh\",\"LSD\",\"Meth\",\"Mushrooms\",\"Nicotine\",\"Semer\",\"VSA\"]\n",
    "\n",
    "drugs_set=feature_set[13:].copy()\n",
    "#features\n",
    "df.columns=feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "younger-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "df_drugs=df[drugs_set].copy()\n",
    "df_people=df.drop(drugs_set, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "everyday-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "# 0 for \"Non-User\", 1 for \"User\" category/labels\n",
    "# CL0 ... CL6\n",
    "for drug in df_drugs:\n",
    "    for i in df_drugs[drug].index:\n",
    "        if  (df_drugs[drug][i]==\"CL0\" or df_drugs[drug][i]==\"CL1\"):\n",
    "            df_drugs[drug][i]=0  # \"Non-User\"\n",
    "        else:\n",
    "            df_drugs[drug][i]=1  # \"User\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compound-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_train,people_test, drugs_train, drugs_test=train_test_split(df_people, df_drugs, test_size=0.33)\n",
    "drugs_subset=[\"Alcohol\",\"Amphet\",\"Mushrooms\",\"Cannabis\",\"Coke\",\"VSA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporate-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrices\n",
    "\n",
    "# mdrugs=len(drugs_subset)\n",
    "# nmodels=len(drug_models)\n",
    "# model_names=[\"Decision Tree\",\"Random Forest\", \"SVM\", \"K-Neighbors\"]\n",
    "\n",
    "# fig, axs = plt.subplots(nmodels, mdrugs, figsize=(20,10),sharex='col',sharey='row')\n",
    "\n",
    "# # for all the 4 types of models:\n",
    "# for j in range(0,nmodels):\n",
    "#     for i in range(0,mdrugs):\n",
    "#         # create confusion matrix\n",
    "#         cm=metrics.confusion_matrix(drugs_test[drugs_subset[i]].values.tolist(),drug_predictions[j][i])\n",
    "#         #display and plot the confusion matrix\n",
    "#         disp=metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=drug_models[j][i].classes_) # model.classes_=[0,1] \n",
    "#         disp.plot(ax=axs[j][i])\n",
    "#         disp.im_.colorbar.remove()\n",
    "#         if i==3:\n",
    "#             disp.ax_.set_title('\\n\\n'+str(model_names[j])+'\\n'+str(drugs_subset[i]))\n",
    "#         else:\n",
    "#             disp.ax_.set_title(drugs_subset[i])\n",
    "        \n",
    "#         precision_recall_micro=metrics.precision_recall_fscore_support(drugs_test[drugs_subset[i]].values.tolist(), drug_predictions[j][i], average='binary')\n",
    "#         precision_recall_micro=precision_recall_micro[:2]\n",
    "# #         print(drugs_subset[i], model_names[j], \"precision:\",precision_recall_micro[0], \"recall:\",precision_recall_micro[1])\n",
    "        \n",
    "#         disp.ax_.set_xlabel('precision:'+str(round(precision_recall_micro[0],4))+ '\\nrecall:'+str(round(precision_recall_micro[1],4))+'\\n')\n",
    "        \n",
    "#         if j==(nmodels-1) and i==3:\n",
    "#             disp.ax_.set_xlabel('precision:'+str(round(precision_recall_micro[0],4))+ '\\nrecall:'+str(round(precision_recall_micro[1],4))+'\\n\\nPredicted Label')\n",
    "            \n",
    "#         disp.ax_.set_ylabel('')\n",
    "#         if i==0:\n",
    "#             disp.ax_.set_ylabel('True label')\n",
    "            \n",
    "        \n",
    "            \n",
    "# fig.suptitle('Confusion Matrices',fontweight =\"bold\", fontsize=20)\n",
    "# plt.subplots_adjust(wspace=0.40, hspace=0.7)\n",
    "# fig.colorbar(disp.im_, ax=axs)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "embedded-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curves\n",
    "\n",
    "# fig, axs = plt.subplots(2,3, figsize=(15,10),sharex='col',sharey='row')\n",
    "\n",
    "# for i in range(0,mdrugs):\n",
    "#     for j in range(0,nmodels):\n",
    "#         #  probability of the class with the greater label\n",
    "#         drug_pred_scores = drug_models[j][i].predict_proba(people_test)[:,1]\n",
    "#         # false positive rate, true positive rate (and threshold \"-\" value but we don't use it here)\n",
    "#         fpr, tpr, _ = metrics.roc_curve(drugs_test[drugs_subset[i]].values.tolist(), drug_pred_scores)\n",
    "#         # area under the ROC curve\n",
    "#         auc=metrics.roc_auc_score(drugs_test[drugs_subset[i]].values.tolist(), drug_pred_scores)\n",
    "# #         print(\"For \"+str(drugs_subset[i])+\", \"+str(model_names[j])+\" area: \" + str(auc))  \n",
    "        \n",
    "#         c=i%3\n",
    "#         r=0\n",
    "#         if i>2:\n",
    "#             r=1\n",
    "#         axs[r,i%3].set_xlabel(\"FPR (False Positive Rate)\")\n",
    "#         axs[r,i%3].set_ylabel(\"TPR (True Positive Rate)\")\n",
    "#         axs[r,i%3].plot(fpr,tpr,label=str(model_names[j])+\" (area: \" + str(round(auc,4))+\")\")\n",
    "#         axs[r,i%3].set_title(drugs_subset[i])\n",
    "#         axs[r,i%3].legend()\n",
    "        \n",
    "# fig.suptitle('ROC Curves and Area Under the Curve per Drug',fontweight =\"bold\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cc14ab-9188-4f15-b33b-1974bb99736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_people\n",
    "# y=df_drugs[drugs_subset]\n",
    "y=df_drugs\n",
    "# X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.33) # people_train,people_test, drugs_train, drugs_test\n",
    "i=5\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c710a-9156-450a-bd02-a2a969cd139c",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation\n",
    "\n",
    "The function cross_val_predict is appropriate for:\n",
    "   - Visualization of predictions obtained from different models.\n",
    "   - Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72b903b-2f03-4840-9a6a-dd4ab0c4be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_crossval(clf, X=df_people, y=df_drugs, target_class=drugs_subset[5], resample='baseline', n=10, scoring = ['accuracy','precision', 'recall','f1']):\n",
    "    # resample = 'baseline', 'over' or 'under'\n",
    "    # y[target_class] must be binary 0 or 1, so you would need to set binary class labels before calling this function\n",
    "    \n",
    "    #### Baseline Aproach\n",
    "    kfold_cv= KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    # create model\n",
    "    if clf==svm.SVC:\n",
    "        model_tf = clf(probability=True)\n",
    "    elif clf==neural_network.MLPClassifier:\n",
    "        model_tf = MLPClassifier(hidden_layer_sizes=(12,8), activation='relu', max_iter=150, batch_size=10, verbose=False)\n",
    "    else:\n",
    "        model_tf = clf()\n",
    "#     X_resampled, y_resampled =  X, y[target_class].astype('int')\n",
    "    imba_pipeline=make_pipeline(model_tf)\n",
    "    \n",
    "    if resample!='baseline':\n",
    "        \n",
    "        #### Over-Sampling Method\n",
    "        if resample=='over':\n",
    "            rs = over_sampling.RandomOverSampler(sampling_strategy='minority',random_state=42)\n",
    "        #### Under-Sampling Method\n",
    "        elif resample=='under':\n",
    "            rs = under_sampling.RandomUnderSampler(sampling_strategy='majority',random_state=42)\n",
    "            \n",
    "#         X_resampled, y_resampled = rs.fit_resample( X, y[target_class].astype('int'))\n",
    "        imba_pipeline=make_pipeline(rs,model_tf )\n",
    "\n",
    "    scores = model_selection.cross_validate(imba_pipeline, X, y[target_class].astype('int'), scoring=scoring, cv=kfold_cv, return_estimator=True)\n",
    "    sorted(scores.keys())\n",
    "    return scores\n",
    "\n",
    "#     print(scores['test_recall'])\n",
    "\n",
    "    # for score in scores:\n",
    "    #     print(score, scores[score],\"\\n\")\n",
    "    \n",
    "#     print(Counter(y_resampled))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e271667d-45d5-4814-a4fc-58c4a428465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold_crossval(clf=tree.DecisionTreeClassifier,X=df_people, y=df_drugs, resample='over')\n",
    "# c=neural_network.MLPClassifier\n",
    "# c=ensemble.GradientBoostingClassifier\n",
    "# kfold_crossval(clf=c,X=df_people, y=df_drugs, resample='over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19086cb6-cfa5-4891-8231-8e9f473f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k['estimator'][2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba38f8c-26db-42ab-ab1a-563dea2f8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=neighbors.KNeighborsClassifier\n",
    "# type(s()).__name__\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749874e3-f420-4e46-9544-edaa68a80ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scores(X,y,targets):\n",
    "    drug_clf_scores={}\n",
    "#     targets=drugs_subset.copy()\n",
    "    clfs={'DT':tree.DecisionTreeClassifier, 'RF':ensemble.RandomForestClassifier, 'KNN':neighbors.KNeighborsClassifier, 'SVM':svm.SVC, 'MLP':neural_network.MLPClassifier, 'GB': ensemble.GradientBoostingClassifier}\n",
    "\n",
    "    for target in targets:\n",
    "\n",
    "        clf_scores={}\n",
    "        for clf_key, clf in clfs.items():\n",
    "\n",
    "            baseline=kfold_crossval(clf=clf, X=X, y=y, target_class=target) #D\n",
    "            over_sampled=kfold_crossval(clf=clf, X=X, y=y, target_class=target, resample='over') #DB1\n",
    "            under_sampled=kfold_crossval(clf=clf, X=X, y=y, target_class=target, resample='under') #DB2\n",
    "\n",
    "            scores=(baseline ,over_sampled, under_sampled)\n",
    "\n",
    "            clf_scores.update({clf_key:scores})    \n",
    "        drug_clf_scores.update({target:clf_scores}) \n",
    "        \n",
    "    return drug_clf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1aed34-ecf9-4ac0-b257-75fe23b2a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_clf_scores['VSA']['RF'][1] #results for VSA: DT , oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdc32180-7a17-4921-b81c-45fb092ce481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###  https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "# # define pipeline\n",
    "# scoring = ['precision', 'recall','f1']\n",
    "# steps = [('over', over_sampling.RandomOverSampler()), ('model', tree.DecisionTreeClassifier())]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "# # evaluate pipeline\n",
    "# kfold_cv= KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# scores = model_selection.cross_validate(pipeline, X, y, scoring=scoring, cv=kfold_cv)\n",
    "# score = scores['f1']\n",
    "# print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f637fe-36ff-46e7-ac8b-7b7161df2f8e",
   "metadata": {},
   "source": [
    "Heart Attack Analysis & Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90b28242-bb94-4526-964b-ed835ed36521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([1.14323187, 1.63299918, 2.89146495, 0.58130527, 1.7913537 ,\n",
       "         1.0617919 , 1.06164813, 0.75957513, 1.13442087, 1.95098686]),\n",
       "  'score_time': array([0.00375414, 0.00373197, 0.00358295, 0.00315785, 0.00314713,\n",
       "         0.00329304, 0.00313878, 0.00353003, 0.0033133 , 0.0034833 ]),\n",
       "  'estimator': [Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))])],\n",
       "  'test_accuracy': array([0.94708995, 0.98412698, 0.98412698, 0.96825397, 0.96808511,\n",
       "         0.9787234 , 0.95744681, 0.95744681, 0.95212766, 0.94148936]),\n",
       "  'test_precision': array([0.94708995, 0.98412698, 0.98412698, 0.96825397, 0.96808511,\n",
       "         0.9787234 , 0.95744681, 0.95744681, 0.95212766, 0.94148936]),\n",
       "  'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "  'test_f1': array([0.97282609, 0.992     , 0.992     , 0.98387097, 0.98378378,\n",
       "         0.98924731, 0.97826087, 0.97826087, 0.97547684, 0.96986301])},\n",
       " {'fit_time': array([8.98967695, 2.68412375, 3.50955606, 4.38531399, 9.46961403,\n",
       "         5.77584791, 3.63881183, 2.09787989, 3.71691275, 6.04700804]),\n",
       "  'score_time': array([0.00362515, 0.00347805, 0.00319982, 0.00352621, 0.0031929 ,\n",
       "         0.004318  , 0.0034411 , 0.00326896, 0.00357127, 0.00350904]),\n",
       "  'estimator': [Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomoversampler',\n",
       "                    RandomOverSampler(random_state=42,\n",
       "                                      sampling_strategy='minority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))])],\n",
       "  'test_accuracy': array([0.62433862, 0.72486772, 0.34920635, 0.3968254 , 0.74468085,\n",
       "         0.4787234 , 0.47340426, 0.59042553, 0.75531915, 0.77659574]),\n",
       "  'test_precision': array([0.98214286, 0.98550725, 0.98461538, 0.98591549, 0.97183099,\n",
       "         1.        , 0.96551724, 0.97247706, 0.95862069, 0.95302013]),\n",
       "  'test_recall': array([0.61452514, 0.7311828 , 0.34408602, 0.38251366, 0.75824176,\n",
       "         0.4673913 , 0.46666667, 0.58888889, 0.77653631, 0.80225989]),\n",
       "  'test_f1': array([0.75601375, 0.83950617, 0.50996016, 0.5511811 , 0.85185185,\n",
       "         0.63703704, 0.62921348, 0.73356401, 0.85802469, 0.87116564])},\n",
       " {'fit_time': array([0.26999187, 0.20692396, 0.15149498, 0.10821986, 0.13697577,\n",
       "         0.08221579, 0.16564608, 0.14128304, 0.18396688, 0.0806191 ]),\n",
       "  'score_time': array([0.00494313, 0.00532603, 0.0044179 , 0.0041163 , 0.00443316,\n",
       "         0.00368595, 0.00347281, 0.00398898, 0.0043509 , 0.003304  ]),\n",
       "  'estimator': [Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))]),\n",
       "   Pipeline(steps=[('randomundersampler',\n",
       "                    RandomUnderSampler(random_state=42,\n",
       "                                       sampling_strategy='majority')),\n",
       "                   ('mlpclassifier',\n",
       "                    MLPClassifier(batch_size=10, hidden_layer_sizes=(12, 8),\n",
       "                                  max_iter=150))])],\n",
       "  'test_accuracy': array([0.05291005, 0.43386243, 0.44444444, 0.56613757, 0.50531915,\n",
       "         0.06914894, 0.32446809, 0.88297872, 0.27659574, 0.15425532]),\n",
       "  'test_precision': array([0.        , 0.96470588, 1.        , 0.99029126, 0.97849462,\n",
       "         1.        , 0.94915254, 0.95930233, 0.95744681, 1.        ]),\n",
       "  'test_recall': array([0.        , 0.44086022, 0.43548387, 0.55737705, 0.5       ,\n",
       "         0.04891304, 0.31111111, 0.91666667, 0.25139665, 0.10169492]),\n",
       "  'test_f1': array([0.        , 0.60516605, 0.60674157, 0.71328671, 0.66181818,\n",
       "         0.09326425, 0.46861925, 0.9375    , 0.39823009, 0.18461538])})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_clf_scores=train_scores(X=df_people,y=df_drugs,targets=drugs_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f268dc67-e5d0-4c7b-940a-83074f5be933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"./data/heart/heart_cleveland_upload.csv\")\n",
    "# df = pd.read_csv(\"./data/heart/o2Saturation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f80cb63b-0bc3-4a53-a704-6d19a0888712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5ef6797b-1508-499e-bd50-9ddea8253a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set=df.columns.values\n",
    "len(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6dc0af-4aeb-443c-85c3-5e271d225883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "df_target=df[drugs_set].copy()\n",
    "df_input=df.drop(drugs_set, axis=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5481d24-576a-48fc-a3c9-d151958616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=[\"ID\",\"Age\",\"Gender\",\"Education\",\"Country\",\"Ethnicity\",\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\",\n",
    "             \"Alcohol\",\"Amphet\",\"Amyl\",\"Benzos\",\"Caff\",\"Cannabis\",\"Choc\",\"Coke\",\"Crack\",\n",
    "             \"Ecstasy\",\"Heroin\",\"Ketamine\",\"Legalh\",\"LSD\",\"Meth\",\"Mushrooms\",\"Nicotine\",\"Semer\",\"VSA\"]\n",
    "\n",
    "drugs_set=feature_set[13:].copy()\n",
    "#features\n",
    "df.columns=feature_set\n",
    "\n",
    "# labels\n",
    "df_drugs=df[drugs_set].copy()\n",
    "df_people=df.drop(drugs_set, axis=1)\n",
    "\n",
    "# create labels\n",
    "# 0 for \"Non-User\", 1 for \"User\" category/labels\n",
    "# CL0 ... CL6\n",
    "for drug in df_drugs:\n",
    "    for i in df_drugs[drug].index:\n",
    "        if  (df_drugs[drug][i]==\"CL0\" or df_drugs[drug][i]==\"CL1\"):\n",
    "            df_drugs[drug][i]=0  # \"Non-User\"\n",
    "        else:\n",
    "            df_drugs[drug][i]=1  # \"User\"\n",
    "            \n",
    "drugs_subset=[\"Alcohol\",\"Amphet\",\"Mushrooms\",\"Cannabis\",\"Coke\",\"VSA\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0e7f65-86c4-4de7-b511-d73695264649",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486f27e-2a00-4924-92bc-f131cff6b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "= pd.read_csv(\"./data/labor/labor-negotiations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc53b68-9e71-426e-918c-0b86229a99fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fa277-98cc-4a50-8c06-3b7609755a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
